{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poverty and inequality effects of new unemployment benefits, payroll tax cuts, and universal payments \n",
    "\n",
    "*By [Max Ghenis](https://www.ubicenter.org/about#h.p_T-QXperbv_x2) and\n",
    "[Nate Golden](https://www.ubicenter.org/about#h.p_T-QXperbv_x2)*\n",
    "\n",
    "*July 2020*\n",
    "\n",
    "## Abstract\n",
    "\n",
    "The expiration of the \\$600-per-week Federal Pandemic Unemployment Compensation (FPUC) program\n",
    "at the end of July 2020 has spurred discussions for new Covid-19 relief legislation in the United States.\n",
    "Proposals for this bill include extending FPUC throughout 2020,\n",
    "cutting payroll taxes, and unconditional payments.\n",
    "We use data from the Current Population Survey between 2009 and 2018\n",
    "to estimate the poverty and inequality effects\n",
    "of a hypothetical FPUC and FPUC extension,\n",
    "compared to budget-neutral payroll tax cuts and universal payments,\n",
    "respectively.\n",
    "Our simulations show that a universal payment would have lowered\n",
    "poverty and inequality similarly to April-to-July FPUC\n",
    "(i.e., the policy that's expiring).\n",
    "However, universal payments would have reduced poverty and inequality\n",
    "significantly more than August-to-December FPUC extensions;\n",
    "for example, it would have reduced poverty twice as much in 2009.\n",
    "Payroll tax cuts would have had much smaller effects than either policy,\n",
    "and universal payments that include children are consistently more\n",
    "effective than adult-only payments.\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "The CARES Act established two major new unemployment insurance reforms:\n",
    "Pandemic Unemployment Assistance (PUA), which expands unemployment benefits to more worker categories,\n",
    "and Federal Pandemic Unemployment Compensation (FPUC), which adds a federally-funded\n",
    "\\$600 per week to all unemployment benefits.\n",
    "While PUA is available for up to 39 weeks through the end of the year,\n",
    "FPUC runs only from [April through July](https://wdr.doleta.gov/directives/attach/UIPL/UIPL_15-20.pdf).\n",
    "\n",
    "Given FPUC's expiration and the Congressional Budget Office's [projections](In July 2020, the Congressional Budget Office [projected](https://www.cbo.gov/data/budget-economic-data#4)\n",
    "that the unemployment rate would remain above 10 percent throughout 2020.),\n",
    "federal lawmakers are preparing for a new relief package.\n",
    "Congressional Democrats are seeking to extend FPUC in full through January, as specified in\n",
    "the House-passed [HEROES Act](https://www.washingtonpost.com/us-policy/2020/05/12/house-democrats-coronavirus-3-trillion/).\n",
    "The Trump administration has proposed [cutting payroll taxes](https://www.washingtonpost.com/us-policy/2020/07/16/payroll-tax-cut-trump-coronavirus/),\n",
    "and members of both parties have spoken of another round of direct payments,\n",
    "following the Recovery Rebates in the CARES Act.\n",
    "\n",
    "FPUC's work disincentives have made it controversial: it replaces\n",
    "[over 100 percent of wages](https://colab.research.google.com/drive/11hRHMXiEYmuvEXKZZoHK9qjePFMk5Nzy) for\n",
    "all workers earning below \\\\$21 per hour, and depending on the state, for workers earning up to \\\\$33 per hour.[^replacement]\n",
    "Capping the wage replacement rate was infeasible due to limitations with state unemployment benefit\n",
    "computer systems.\n",
    "Its proponents emphasize income stabilization and the need to reduce work to prevent Covid infections.\n",
    "To the extent that FPUC may be making it harder to find workers, payroll tax cuts can offset that effect.\n",
    "\n",
    "[^replacement]: Assumes that workers have worked full-time at a constant wage for the past several quarters.\n",
    "\n",
    "Distributional effects have been less prominent in the debates over Covid relief policies;\n",
    "this paper aims to remedy that.\n",
    "\n",
    "\n",
    "## Data\n",
    "\n",
    "We use the [Current Population Survey March Supplement](https://www.census.gov/data/datasets/time-series/demo/cps/cps-asec.html)\n",
    "from 2009 to 2018, extracted from the [IPUMS](https://cps.ipums.org/) service.\n",
    "The [Supplemental Poverty Measure](https://www.census.gov/topics/income-poverty/supplemental-poverty-measure.html) was introduced in 2009,\n",
    "while 2018 is the latest survey year available as of this writing.\n",
    "\n",
    "We extract fields used for tax and poverty analysis, as well as the \"[number of weeks](https://cps.ipums.org/cps-action/variables/WKSUNEM1#description_section),\n",
    "in single weeks, that the respondent looked for work or was on layoff during the preceding calendar year.\"\n",
    "This field allows us to estimate the total FPUC benefits for each respondent.\n",
    "\n",
    "[TODO:] All dollar values are scaled to 2020 dollars using the CPI-U-RS price deflator.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "\n",
    "\n",
    "### Imputing FPUC unemployment benefits\n",
    "\n",
    "The CPS only provides the number of weeks each respondent was unemployed, not the specific calendar weeks.\n",
    "Since the specific time periods--\n",
    "April to July to model past policy, and August to December to model proposed policy--\n",
    "are relevant for the simulation, we impute the calendar weeks of unemployment for each respondent.\n",
    "We assume that the unemployment spell is continuous, and therefore only affected but the\n",
    "starting week, which we assign randomly as week $0$ to week $52 - WeeksUnemployed$, to ensure that the\n",
    "unemployment spell is fully within the survey year.\n",
    "\n",
    "We then calculate the total weeks from April to July and from August to December when the person\n",
    "was unemployed, and multiply those numbers by \\$600 to simulate FPUC or the FPUC extension, respectively.\n",
    "\n",
    "\n",
    "### Tax simulation\n",
    "\n",
    "We use the open-source [Tax-Calculator](https://pslmodels.github.io/Tax-Calculator/)\n",
    "software for simulating FPUC tax liabilities.\n",
    "This involves grouping people into tax units[^taxunits] and calculating tax-relevant\n",
    "fields from each tax unit's aggregate CPS responses.\n",
    "We then calculate each tax unit's federal tax liability with and without FPUC--\n",
    "applying 2020 tax law for all years--and store the difference as the FPUC tax.\n",
    "\n",
    "[^taxunits]: Our code for tax unit creation was based on similar code by\n",
    "[Ernie Tedeschi](https://github.com/ernietedeschi/tcpoverty),\n",
    "[Sam Portnow](https://users.nber.org/~taxsim/to-taxsim/cps/cps-portnow/TaxSimRScriptForDan.R),\n",
    "and the Policy Simulation Library's\n",
    "[Tax-Data project](https://github.com/PSLmodels/taxdata/tree/master/cps_data),\n",
    "which creates tax units from non-IPUMS CPS records.\n",
    "\n",
    "To identify the net-of-tax FPUC benefits for each person,[^taxunitperson]\n",
    "we allocate  the tax unit's FPUC tax across individuals in proportion to their FPUC benefits.\n",
    "This leaves us with the net-of-tax FPUC benefits for each person in the sample.\n",
    "\n",
    "[^taxunitperson]: We need the tax liability for each person because\n",
    "some tax units include people from multiple SPM units.\n",
    "\n",
    "### Poverty estimation\n",
    "\n",
    "SPM poverty rates are calculated by grouping individuals into *SPM units*,\n",
    "which are sub-household groups that the Bureau of Labor Statistics identifies\n",
    "as sharing resources.\n",
    "Each SPM unit then has its own poverty threshold---based on composition and\n",
    "housing situation---and resources---\n",
    "based on income, taxes, mandatory spending categories, and transfers.\n",
    "SPM units are determined to classified as poor if their poverty threshold\n",
    "exceeds their resources.\n",
    "\n",
    "To calculate this, we group each person into their SPM unit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 27.6 TiB for an array with shape (1948983, 1948983) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7322c99ad171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m                \u001b[0;34m'p23250'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fica'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_e00200'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'e00600'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'e01500'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                'e00200p', 'e00200s', 'e00200']\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDOLLAR_VALS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDOLLAR_VALS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minflate2020\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \"\"\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(self, other, axis, level, fill_value)\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0mpass_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpass_op\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_logical\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m             return _combine_series_frame(\n\u001b[0;32m--> 776\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    777\u001b[0m             )\n\u001b[1;32m    778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36m_combine_series_frame\u001b[0;34m(self, other, func, fill_value, axis, level)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m     \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"outer\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_match_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   3832\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3833\u001b[0m             \u001b[0mfill_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3834\u001b[0;31m             \u001b[0mbroadcast_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbroadcast_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3835\u001b[0m         )\n\u001b[1;32m   3836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36malign\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m   8484\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8485\u001b[0m                 \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8486\u001b[0;31m                 \u001b[0mfill_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_axis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8487\u001b[0m             )\n\u001b[1;32m   8488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_align_series\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[1;32m   8605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8606\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlidx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8607\u001b[0;31m                     \u001b[0mfdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8608\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8609\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must specify axis=0 or 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m             \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m             new_blocks = [\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                 blocks.append(\n\u001b[0;32m-> 1333\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_na_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m                 )\n\u001b[1;32m   1335\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_make_na_block\u001b[0;34m(self, placement, fill_value)\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_dtype_from_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1369\u001b[0;31m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1370\u001b[0m         \u001b[0mblock_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 27.6 TiB for an array with shape (1948983, 1948983) and data type float64"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SETUP\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import taxcalc as tc\n",
    "import microdf as mdf\n",
    "import plotly.express as px\n",
    "import pandas_datareader as pdr  # For CPI series.\n",
    "\n",
    "# For setting a random period of unemployment given a person's duration.\n",
    "np.random.seed(0)\n",
    "\n",
    "person = pd.read_csv('ui/data/cps.csv.gz')\n",
    "\n",
    "\"\"\"\n",
    "# Prepare data\n",
    "\n",
    "* Loads and preprocesses IPUMS ASEC from 2009 to 2018\n",
    "* Simulates FPUC unemployment benefits\n",
    "* Calculates tax liability from unemployment benefits via `taxcalc`\n",
    "* Calculates budget-neutral UBI and payroll tax cuts\n",
    "* Aggregates to SPM unit level\n",
    "* Joins back to person record\n",
    "* Exports person and SPM unit records\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "## PREPROCESSING\n",
    "\"\"\"\n",
    "\n",
    "%run 'ui/convert_asec_taxcalc.py'\n",
    "%run 'ui/make_tax_units.py'\n",
    "\n",
    "# Set columns to lowercase and to 0 or null as appropriate.\n",
    "prep_ipum(person)\n",
    "# Add taxid and related fields.\n",
    "tax_unit_id(person)\n",
    "# Add other person-level columns in taxcalc form.\n",
    "person = convert_asec_person_taxcalc(person)\n",
    "# 99 is the missing code for wksunem1.\n",
    "# Note: Missing codes for features used in taxcalc are recoded in\n",
    "# convert_asec_taxcalc.py.\n",
    "person.loc[person.wksunem1 == 99, 'wksunem1'] = 0\n",
    "# The 2014 file was released in two ways, so weights must be halved.\n",
    "person.asecwt *= np.where(person.year == 2014, 0.5, 1)\n",
    "person.spmwt *= np.where(person.year == 2014, 0.5, 1)\n",
    "\n",
    "# Adjust all dollar values to 2020.\n",
    "cpiu = pdr.get_data_fred('CPIAUCSL', '2009-01-01')\n",
    "# Filter to January.\n",
    "cpiu = cpiu[cpiu.index.month == 1]\n",
    "cpiu.index = cpiu.index.year\n",
    "# Multiplier to 2020.\n",
    "cpiu['inflate2020'] = cpiu.CPIAUCSL[2020] / cpiu.CPIAUCSL\n",
    "# Survey year is the reported year minus 1.\n",
    "person['FLPDYR'] = person.year - 1\n",
    "person = person.merge(cpiu[['inflate2020']], left_on='FLPDYR',\n",
    "                      right_index=True)\n",
    "DOLLAR_VALS = ['spmtotres', 'spmthresh',\n",
    "               'e02400', 'e01700', 'e00300', 'e02300', 'e00650', 'incrent',\n",
    "               'p23250', 'fica', '_e00200', 'e00600', 'e01500', \n",
    "               'e00200p', 'e00200s', 'e00200']\n",
    "person[DOLLAR_VALS] = person[DOLLAR_VALS] * person.inflate2020\n",
    "\n",
    "\"\"\"\n",
    "## Add UI to person records\n",
    "\n",
    "Assume that unemployment blocks are contiguous and randomly distributed.\n",
    "\"\"\"\n",
    "person['ui_start'] = np.random.randint(1, 53 - person.wksunem1,\n",
    "                                       person.shape[0])\n",
    "person['ui_end'] = person.ui_start + person.wksunem1\n",
    "\n",
    "FPUC_START = 13  # April was the 13th week.\n",
    "FPUC_MAX_WEEKS = 17  # April to July.\n",
    "FPUC2_START = FPUC_START + FPUC_MAX_WEEKS\n",
    "FPUC2_MAX_WEEKS = 22  # August to December.\n",
    "FPUC_WEEKLY_BEN = 600\n",
    "person['fpuc_weeks'] = np.fmax(\n",
    "    0, np.fmin(person.ui_end - FPUC_START,\n",
    "               np.fmin(person.wksunem1, FPUC_MAX_WEEKS)))\n",
    "person['fpuc2_weeks'] = np.fmax(\n",
    "    0, np.fmin(person.ui_end - FPUC2_START,\n",
    "               np.fmin(person.wksunem1, FPUC2_MAX_WEEKS)))\n",
    "person['fpuc'] = FPUC_WEEKLY_BEN * person.fpuc_weeks\n",
    "person['fpuc2'] = person.fpuc + FPUC_WEEKLY_BEN * person.fpuc2_weeks\n",
    "\n",
    "# Checks\n",
    "assert person.fpuc_weeks.max() == FPUC_MAX_WEEKS\n",
    "assert person.fpuc2_weeks.max() == FPUC2_MAX_WEEKS\n",
    "assert person.fpuc_weeks.min() == person.fpuc2_weeks.min() == 0\n",
    "\n",
    "# Store original unemployment benefits.\n",
    "person['e02300_orig'] = person.e02300\n",
    "\n",
    "\"\"\"\n",
    "## Create tax units and calculate tax liability\n",
    "\"\"\"\n",
    "person['RECID'] = person.FLPDYR * 1e9 + person.taxid\n",
    "\n",
    "def get_taxes(tu):\n",
    "    \"\"\" Calculates taxes by running taxcalc on a tax unit DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        tu: Tax unit DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        Series with tax liability for each tax unit.\n",
    "    \"\"\"\n",
    "    return mdf.calc_df(records=tc.Records(tu, weights=None, gfactors=None),\n",
    "                       # year doesn't matter without weights or gfactors.\n",
    "                       year=2020).tax.values\n",
    "\n",
    "# Create tax unit dataframe.\n",
    "tu = create_tax_unit(person)\n",
    "tu['tax'] = get_taxes(tu)\n",
    "\n",
    "# Simulate FPUC.\n",
    "\n",
    "# Create tax unit dataframe.\n",
    "person.e02300 = person.e02300_orig + person.fpuc\n",
    "tu_fpuc = create_tax_unit(person)\n",
    "tu['e02300_fpuc'] = tu_fpuc.e02300\n",
    "tu['tax_fpuc'] = get_taxes(tu_fpuc)\n",
    "del tu_fpuc\n",
    "\n",
    "# Simulate extended FPUC.\n",
    "\n",
    "# Create tax unit dataframe.\n",
    "person.e02300 = person.e02300_orig + person.fpuc2\n",
    "tu_fpuc2 = create_tax_unit(person)\n",
    "tu['e02300_fpuc2'] = tu_fpuc2.e02300\n",
    "tu['tax_fpuc2'] = get_taxes(tu_fpuc2)\n",
    "del tu_fpuc2\n",
    "\n",
    "# Change person e02300 back.\n",
    "person.e02300 = person.e02300_orig\n",
    "\n",
    "\"\"\"\n",
    "## Merge back to the person level\n",
    "\n",
    "Have each person pay the share of tax differences in proportion with their\n",
    "FPUC.\n",
    "\"\"\"\n",
    "\n",
    "tu['fpuc_total'] = tu.e02300_fpuc - tu.e02300\n",
    "tu['fpuc2_total'] = tu.e02300_fpuc2 - tu.e02300\n",
    "tu['fpuc_tax_total'] = tu.tax_fpuc - tu.tax\n",
    "tu['fpuc2_tax_total'] = tu.tax_fpuc2 - tu.tax\n",
    "\n",
    "person = person.merge(tu[['RECID', 'fpuc_total', 'fpuc2_total',\n",
    "                          'fpuc_tax_total', 'fpuc2_tax_total']],\n",
    "                      on='RECID')\n",
    "\n",
    "for i in ['fpuc', 'fpuc2']:\n",
    "    person[i + '_tax'] = np.where(person[i + '_total'] == 0, 0,\n",
    "        person[i + '_tax_total'] * person[i] / person[i + '_total'])\n",
    "    person[i + '_net'] = person[i] - person[i + '_tax']\n",
    "    \n",
    "# Checks that the totals match by person and tax unit, then garbage-collect.\n",
    "assert np.allclose(tu.fpuc_total.sum(), person.fpuc.sum())\n",
    "assert np.allclose(tu.fpuc2_total.sum(), person.fpuc2.sum())\n",
    "assert np.allclose(tu.fpuc_tax_total.sum(), person.fpuc_tax.sum())\n",
    "assert np.allclose(tu.fpuc2_tax_total.sum(), person.fpuc2_tax.sum())\n",
    "del tu\n",
    "\n",
    "\"\"\"\n",
    "## Calculate budget-neutral UBIs and payroll taxes\n",
    "\"\"\"\n",
    "\n",
    "def single_year_summary(year):\n",
    "    fpuc_budget = mdf.weighted_sum(person[person.FLPDYR == year],\n",
    "                                   'fpuc_net', 'asecwt')\n",
    "    fpuc1_2_budget = mdf.weighted_sum(person[person.FLPDYR == year],\n",
    "                                      'fpuc2_net', 'asecwt')\n",
    "    fpuc2_budget = fpuc1_2_budget - fpuc_budget\n",
    "    pop = person[person.FLPDYR == year].asecwt.sum()\n",
    "    adult_pop = person[(person.FLPDYR == year) &\n",
    "                       (person.age > 17)].asecwt.sum()\n",
    "    total_fica = mdf.weighted_sum(person[person.FLPDYR == year],\n",
    "                                  'fica', 'asecwt')\n",
    "    fpuc_ubi = fpuc_budget / pop\n",
    "    fpuc_adult_ubi = fpuc_budget / adult_pop\n",
    "    fpuc_fica_pct_cut = 100 * fpuc_budget / total_fica\n",
    "    # Note: FPUC2 includes FPUC1.\n",
    "    fpuc2_ubi = fpuc2_budget / pop\n",
    "    fpuc2_adult_ubi = fpuc2_budget / adult_pop\n",
    "    fpuc2_fica_pct_cut = 100 * fpuc2_budget / total_fica\n",
    "    return pd.Series([fpuc_budget, fpuc2_budget, pop, adult_pop, total_fica,\n",
    "                      fpuc_ubi, fpuc_adult_ubi, fpuc_fica_pct_cut,\n",
    "                      fpuc2_ubi, fpuc2_adult_ubi, fpuc2_fica_pct_cut])\n",
    "\n",
    "OVERALL_YEARLY_METRICS = ['fpuc_budget', 'fpuc2_budget', 'pop', 'adult_pop',\n",
    "                          'total_fica']\n",
    "FPUC_YEARLY_METRICS = ['fpuc_ubi', 'fpuc_adult_ubi', 'fpuc_fica_pct_cut']\n",
    "FPUC2_YEARLY_METRICS = ['fpuc2_ubi', 'fpuc2_adult_ubi', 'fpuc2_fica_pct_cut']\n",
    "all_metrics = (\n",
    "    OVERALL_YEARLY_METRICS + FPUC_YEARLY_METRICS + FPUC2_YEARLY_METRICS)\n",
    "DISPLAY_METRICS = {\n",
    "    'fpuc_budget': 'Cost of FPUC',\n",
    "    'fpuc2_budget': 'Cost of expanding FPUC',\n",
    "    'pop': 'Population',\n",
    "    'adult_pop': 'Adult population',\n",
    "    'total_fica': 'Total FICA',\n",
    "    'fpuc_ubi': 'Universal one-time payment (FPUC)',\n",
    "    'fpuc_adult_ubi': 'Adult one-time payment (FPUC)',\n",
    "    'fpuc_fica_pct_cut': 'FICA % cut (FPUC)',\n",
    "    'fpuc2_ubi': 'Universal one-time payment (FPUC2)',\n",
    "    'fpuc2_adult_ubi': 'Adult one-time payment (FPUC2)',\n",
    "    'fpuc2_fica_pct_cut': 'FICA % cut (FPUC2)'\n",
    "}\n",
    "\n",
    "year_summary = pd.DataFrame({'FLPDYR': person.FLPDYR.unique()})\n",
    "year_summary[all_metrics] = year_summary.FLPDYR.apply(single_year_summary)\n",
    "\n",
    "person = person.merge(\n",
    "    year_summary[['FLPDYR'] + FPUC_YEARLY_METRICS + FPUC2_YEARLY_METRICS],\n",
    "    on='FLPDYR')\n",
    "\n",
    "\"\"\"\n",
    "Run calculations on all fields (except `fpuc_ubi` which already works).\n",
    "\"\"\"\n",
    "\n",
    "# Zero out adult UBIs for children.\n",
    "person.loc[person.age < 18, 'fpuc_adult_ubi'] = 0\n",
    "# Calculate total FICA cut by multiplying FICA by % cut.\n",
    "# Divide by 100 as it was previously multiplied by 100 for table displaying.\n",
    "person['fpuc_fica_cut'] = person.fica * person.fpuc_fica_pct_cut / 100\n",
    "# Similar process for FPUC2, but also adding fpuc_net since this is on top\n",
    "# of the existing FPUC.\n",
    "person['fpuc2_ubi'] = person.fpuc_net + person.fpuc2_ubi\n",
    "person['fpuc2_adult_ubi'] = (person.fpuc_net + \n",
    "                             np.where(person.age > 17,\n",
    "                                      person.fpuc2_adult_ubi, 0))\n",
    "person['fpuc2_fica_cut'] = (person.fpuc_net +\n",
    "                             person.fica * person.fpuc2_fica_pct_cut / 100)\n",
    "\n",
    "\"\"\"\n",
    "Verify the `fpuc` and `fpuc2` have equal costs, respectively, in each year.\n",
    "\"\"\"\n",
    "for year in person.FLPDYR.unique():\n",
    "    tmp = person[person.FLPDYR == year]\n",
    "    fpuc = mdf.weighted_sum(tmp, 'fpuc_net', 'asecwt')\n",
    "    assert np.allclose(fpuc, mdf.weighted_sum(tmp, 'fpuc_ubi', 'asecwt'))\n",
    "    assert np.allclose(fpuc, \n",
    "                       mdf.weighted_sum(tmp, 'fpuc_adult_ubi', 'asecwt'))\n",
    "    assert np.allclose(fpuc, mdf.weighted_sum(tmp, 'fpuc_fica_cut', 'asecwt'))\n",
    "    fpuc2 = mdf.weighted_sum(tmp, 'fpuc2_net', 'asecwt')\n",
    "    assert np.allclose(fpuc2, mdf.weighted_sum(tmp, 'fpuc2_ubi', 'asecwt'))\n",
    "    assert np.allclose(fpuc2, \n",
    "                       mdf.weighted_sum(tmp, 'fpuc2_adult_ubi', 'asecwt'))\n",
    "    assert np.allclose(fpuc2, mdf.weighted_sum(tmp,\n",
    "                                               'fpuc2_fica_cut', 'asecwt'))\n",
    "del tmp\n",
    "\n",
    "\"\"\"\n",
    "## Aggregate to SPM units\n",
    "\"\"\"\n",
    "\n",
    "SPM_COLS = ['FLPDYR', 'spmfamunit', 'spmtotres', 'spmthresh', 'spmwt']\n",
    "CHG_COLS = ['fpuc_net', 'fpuc_ubi', 'fpuc_adult_ubi', 'fpuc_fica_cut',\n",
    "            'fpuc2_net', 'fpuc2_ubi', 'fpuc2_adult_ubi', 'fpuc2_fica_cut']\n",
    "spmu = person.groupby(SPM_COLS)[CHG_COLS].sum().reset_index()\n",
    "for i in CHG_COLS:\n",
    "    spmu['spmtotres_' + i] = spmu.spmtotres + spmu[i]\n",
    "    \n",
    "\"\"\"\n",
    "## Map back to persons\n",
    "\"\"\"\n",
    "# Shrink the data.\n",
    "person = person[['asecwt', 'age', 'race', 'sex'] + CHG_COLS + SPM_COLS]\n",
    "\n",
    "spm_resource_cols = ['spmtotres_' + i for i in CHG_COLS]\n",
    "SPMU_MERGE_COLS = ['spmfamunit', 'FLPDYR']\n",
    "person = person.merge(spmu[SPMU_MERGE_COLS + spm_resource_cols],\n",
    "                      on=SPMU_MERGE_COLS)\n",
    "# Poverty flags.\n",
    "for i in CHG_COLS:\n",
    "    person['spmpoor_' + i ] = person['spmtotres_' + i] < person.spmthresh\n",
    "# Also calculate baseline.\n",
    "person['spmpoor'] = person.spmtotres < person.spmthresh\n",
    "\n",
    "SPM_OUTCOLS = SPM_COLS + spm_resource_cols\n",
    "spmu = spmu[SPM_OUTCOLS]\n",
    "\n",
    "PERSON_OUTCOLS = (['asecwt', 'age', 'race', 'sex', 'spmpoor'] + \n",
    "                  CHG_COLS + spm_resource_cols + SPM_COLS +\n",
    "                  ['spmpoor_' + i for i in CHG_COLS])\n",
    "person = person[PERSON_OUTCOLS]\n",
    "\n",
    "\n",
    "# Print overall summary\n",
    "print(\"All figures in millions.\")\n",
    "(year_summary.set_index('FLPDYR')[OVERALL_YEARLY_METRICS].rename(\n",
    "    columns=DISPLAY_METRICS) / 1e6).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Print reform parameter summary.\n",
    "(year_summary.set_index('FLPDYR')[\n",
    "    FPUC_YEARLY_METRICS + FPUC2_YEARLY_METRICS].rename(\n",
    "    columns=DISPLAY_METRICS)).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "### FPUC thus far\n",
    "\n",
    "In most of the last decade, FPUC would have reduced poverty more than the alternatives.\n",
    "However, in 2009 and 2010, when economic conditions most closely resembled today's,\n",
    "universal transfers were more effective.\n",
    "\n",
    "In all years, universal transfers and FPUC outperformed payments to adults only,\n",
    "and especially outperformed the payroll tax cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def pov(reform, year, age_group='All', race='All'):\n",
    "    \"\"\" Calculate the poverty rate under the specified reform for the\n",
    "        specified population.\n",
    "        Note: All arguments refer to the poverty population, not the reform.\n",
    "    \n",
    "    Args:\n",
    "        reform: One of CHG_COLS. If None, provides the baseline rate.\n",
    "        year: Year of the data (year before CPS survey year).\n",
    "        age_group: Age group, either\n",
    "            - 'Children' (under 18)\n",
    "            - 'Adults' (18 or over)\n",
    "            - 'All'\n",
    "        race: Race code to filter to. Defaults to 'All'.\n",
    "        \n",
    "    Returns:\n",
    "        2018 SPM poverty rate.\n",
    "    \"\"\"\n",
    "    # Select the relevant poverty column for the reform.\n",
    "    if reform == 'baseline':\n",
    "        poverty_col = 'spmpoor'\n",
    "    else:\n",
    "        poverty_col = 'spmpoor_' + reform\n",
    "    # Filter by year.\n",
    "    target_persons = person[person.FLPDYR == year]\n",
    "    # Filter by age group.\n",
    "    if age_group == 'Children':\n",
    "        target_persons = target_persons[target_persons.age < 18]\n",
    "    elif age_group == 'Adults':\n",
    "        target_persons = target_persons[target_persons.age >= 18]\n",
    "    # Filter by race.\n",
    "    if race != 'All':\n",
    "        target_persons = target_persons[target_persons.race == race]\n",
    "    # Return poverty rate (weighted average of poverty flag).\n",
    "    return mdf.weighted_mean(target_persons, poverty_col, 'asecwt')\n",
    "\n",
    "\n",
    "def pov_row(row):\n",
    "    \"\"\" Calculate poverty based on parameters specified in the row.\n",
    "    \n",
    "    Args:\n",
    "        row: pandas Series.\n",
    "        \n",
    "    Returns:\n",
    "        2018 SPM poverty rate.\n",
    "    \"\"\"\n",
    "    return pov(row.reform, row.year, row.age_group, row.race)\n",
    "\n",
    "pov_rates = mdf.cartesian_product({'reform': ['baseline'] + CHG_COLS,\n",
    "                                   'year': person.FLPDYR.unique(),\n",
    "                                   'age_group': ['All', 'Children', 'Adults'],\n",
    "                                   'race': ['All', 200]})  # 200 means Black.\n",
    "pov_rates['pov'] = 100 * pov_rates.apply(pov_row, axis=1)\n",
    "\n",
    "\"\"\"\n",
    "### Poverty gap and inequality\n",
    "Calculate these for all people and SPM units, without breaking out by age or\n",
    "race.\n",
    "\"\"\"\n",
    "\n",
    "def pov_gap_b(reform, year):\n",
    "    if reform == 'baseline':\n",
    "        resource_col = 'spmtotres'\n",
    "    else:\n",
    "        resource_col = 'spmtotres_' + reform\n",
    "    tmp = spmu[spmu.FLPDYR == year]\n",
    "    pov_gap = np.maximum(tmp.spmthresh - tmp[resource_col], 0)\n",
    "    return (pov_gap * tmp.spmwt).sum() / 1e9\n",
    "\n",
    "def pov_gap_row(row):\n",
    "    return pov_gap_b(row.reform, row.year)\n",
    "\n",
    "pov_gap_ineq = pov_rates[['reform', 'year']].drop_duplicates()\n",
    "pov_gap_ineq['pov_gap_b'] = pov_gap_ineq.apply(pov_gap_row, axis=1)\n",
    "\n",
    "\"\"\"\n",
    "### Inequality\n",
    "\n",
    "By individual based on their percentage of SPM resources.\n",
    "\"\"\"\n",
    "\n",
    "def gini(reform, year):\n",
    "    if reform == 'baseline':\n",
    "        resource_col = 'spmtotres'\n",
    "    else:\n",
    "        resource_col = 'spmtotres_' + reform\n",
    "    tmp = person[person.FLPDYR == year]\n",
    "    return mdf.gini(tmp[resource_col], tmp.asecwt)\n",
    "\n",
    "def gini_row(row):\n",
    "    return gini(row.reform, row.year)\n",
    "\n",
    "pov_gap_ineq['gini'] = pov_gap_ineq.apply(gini_row, axis=1)\n",
    "\n",
    "\"\"\"\n",
    "## Postprocess\n",
    "\n",
    "Create columns for displaying and grouping each reform.\n",
    "\"\"\"\n",
    "\n",
    "REFORM_DISPLAY = {\n",
    "    'baseline': 'Baseline',\n",
    "    'fpuc_net': '$600 per week UI',\n",
    "    'fpuc_ubi': 'Payment to everyone',\n",
    "    'fpuc_adult_ubi': 'Payment to adults',\n",
    "    'fpuc_fica_cut': 'Payroll tax cut',\n",
    "    'fpuc2_net': 'Extend $600 per week',\n",
    "    'fpuc2_ubi': 'Payment to everyone',\n",
    "    'fpuc2_adult_ubi': 'Payment to adults',\n",
    "    'fpuc2_fica_cut': 'Payroll tax cut'\n",
    "}\n",
    "\n",
    "REFORM_GROUP = {\n",
    "    'baseline': 'Baseline',\n",
    "    'fpuc_net': 'fpuc',\n",
    "    'fpuc_ubi': 'fpuc',\n",
    "    'fpuc_adult_ubi': 'fpuc',\n",
    "    'fpuc_fica_cut': 'fpuc',\n",
    "    'fpuc2_net': 'fpuc2',\n",
    "    'fpuc2_ubi': 'fpuc2',\n",
    "    'fpuc2_adult_ubi': 'fpuc2',\n",
    "    'fpuc2_fica_cut': 'fpuc2'\n",
    "}\n",
    "\n",
    "for i in [pov_rates, pov_gap_ineq]:\n",
    "    i['reform_display'] = i.reform.map(REFORM_DISPLAY)\n",
    "    i['reform_group'] = i.reform.map(REFORM_GROUP)\n",
    "    i['baseline'] = np.where(i.reform_group == 'fpuc', 'baseline', 'fpuc_net')\n",
    "    \n",
    "\"\"\"\n",
    "### Calculate % changes from relevant baselines\n",
    "\"\"\"\n",
    "\n",
    "POV_RATES_KEYS = ['year', 'age_group', 'race']  # Plus reform/baseline\n",
    "POV_GAP_INEQ_KEYS = ['year']\n",
    "BASELINES = ['baseline', 'fpuc_net']\n",
    "\n",
    "pov_rates_baselines = pov_rates[pov_rates.reform.isin(\n",
    "    BASELINES)][POV_RATES_KEYS + ['reform', 'pov']]\n",
    "pov_rates_baselines.rename(columns={'reform': 'baseline',\n",
    "                                    'pov': 'baseline_pov'}, inplace=True)\n",
    "pov_rates2 = pov_rates[pov_rates.reform != 'baseline'].merge(\n",
    "    pov_rates_baselines, on=POV_RATES_KEYS + ['baseline'])\n",
    "pov_rates2['pov_pc'] = 100 * (pov_rates2.pov / pov_rates2.baseline_pov - 1)\n",
    "\n",
    "pov_gap_ineq_baselines = pov_gap_ineq[\n",
    "    pov_gap_ineq.reform.isin(BASELINES)][\n",
    "    POV_GAP_INEQ_KEYS + ['reform', 'pov_gap_b', 'gini']]\n",
    "pov_gap_ineq_baselines.rename(columns={'reform': 'baseline',\n",
    "                                       'pov_gap_b': 'baseline_pov_gap_b',\n",
    "                                       'gini': 'baseline_gini'}, inplace=True)\n",
    "pov_gap_ineq2 = pov_gap_ineq[pov_gap_ineq.reform != 'baseline'].merge(\n",
    "    pov_gap_ineq_baselines, on=POV_GAP_INEQ_KEYS + ['baseline'])\n",
    "pov_gap_ineq2['pov_gap_pc'] = 100 * (pov_gap_ineq2.pov_gap_b /\n",
    "                                     pov_gap_ineq2.baseline_pov_gap_b - 1)\n",
    "pov_gap_ineq2['gini_pc'] = 100 * (pov_gap_ineq2.gini /\n",
    "                                  pov_gap_ineq2.baseline_gini - 1)\n",
    "\n",
    "## Charts\n",
    "\n",
    "# Colors from https://material.io/design/color/the-color-system.html\n",
    "BLUE = '#1976D2'\n",
    "GRAY = '#BDBDBD'\n",
    "RED = '#C62828'\n",
    "LIGHT_BLUE = '#64B5F6'\n",
    "\n",
    "COLOR_MAP = {\n",
    "    '$600 per week UI': GRAY,\n",
    "    'Extend $600 per week': GRAY,\n",
    "    'Payroll tax cut': RED,\n",
    "    'Payment to everyone': BLUE,\n",
    "    'Payment to adults': LIGHT_BLUE\n",
    "}\n",
    "\n",
    "def line_graph(df, group, y, yaxis_title, title,\n",
    "               x='year', color='reform_display', xaxis_title=''):\n",
    "    \"\"\"Style for line graphs.\n",
    "    \n",
    "    Arguments\n",
    "        df: DataFrame with data to be plotted.\n",
    "        group: Reform group, either 'fpuc' (against baseline), or\n",
    "            'fpuc2' (against FPUC baseline).\n",
    "        y: Column name to plot on the y axis.\n",
    "        yaxis_title: y axis title.\n",
    "        title: Plot title.\n",
    "        x: The column name for the x axis. Defaults to 'year'.\n",
    "        color: The string representing the column to show different colors of.\n",
    "            Defaults to 'reform_display'.\n",
    "        xaxis_title: x axis title. Defaults to '' (since the year is obvious).\n",
    "    \n",
    "    Returns\n",
    "        Nothing. Shows the plot.\n",
    "    \"\"\"\n",
    "    df = df[df.reform_group == group]\n",
    "    if group == 'fpuc':\n",
    "        yaxis_title += ' from baseline'\n",
    "        title += ' from baseline'\n",
    "    else:\n",
    "        yaxis_title += ' from Apr-Jul FPUC baseline'\n",
    "        title += ' moving forward'\n",
    "    is_pc = y[-3:] == '_pc'\n",
    "    if is_pc:\n",
    "        df = df.round(2)\n",
    "    fig = px.line(df, x=x, y=y, color=color, color_discrete_map=COLOR_MAP)\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=xaxis_title,\n",
    "        yaxis_title=yaxis_title,\n",
    "        font=dict(family='Roboto'),\n",
    "        hovermode='x',\n",
    "        plot_bgcolor='white',\n",
    "        legend_title_text='' \n",
    "    )\n",
    "    if y == 'pov_gap_b':\n",
    "        fig.update_layout(yaxis_tickprefix='$', yaxis_ticksuffix='B')\n",
    "    elif y == 'pov_rate' or is_pc:  # Rate or percent changes.\n",
    "        fig.update_layout(yaxis_ticksuffix='%')\n",
    "    if is_pc:\n",
    "        # Calculate a range to show so that the 0% zeroline is visible.\n",
    "        ymin = df[y].min()\n",
    "        ymax = df[y].max()\n",
    "        if ymax < 0:\n",
    "            ymax = 0\n",
    "        yrange = ymax - ymin\n",
    "        ymin_vis = ymin - 0.1 * yrange\n",
    "        ymax_vis = ymax + 0.1 * yrange\n",
    "        fig.update_yaxes(zeroline=True, zerolinewidth=0.5, \n",
    "                         zerolinecolor='lightgray',\n",
    "                         range=[ymin_vis, ymax_vis])\n",
    "\n",
    "    fig.update_traces(mode='markers+lines', hovertemplate=None)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# Round for the hover text.\n",
    "line_graph(pov_rates2[(pov_rates2.age_group == 'All') &\n",
    "                      (pov_rates2.race == 'All')],\n",
    "           group='fpuc', y='pov_pc',\n",
    "           yaxis_title='Change in SPM poverty rate',\n",
    "           title='Poverty reduction by reform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The poverty gap is an alternative poverty measure which quantifies the total\n",
    "amount we'd have to distribute to end poverty.\n",
    "Since we would have to give more to people who are farther below the poverty line,\n",
    "this measure goes beyond the poverty rate in also measuring the severity of poverty.\n",
    "\n",
    "<note: add a trend of the total poverty gap?>\n",
    "\n",
    "Over the past decade, each of FPUC, universal transfers, and adult-only transfers reduce \n",
    "the poverty gap similarly--and far more than the payroll tax cut.\n",
    "As in the poverty rate case, the universal transfers slightly outperform in the\n",
    "2009 recession, while FPUC slightly outperforms in the rest of the period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Round for the hover text.\n",
    "line_graph(pov_gap_ineq2, group='fpuc', y='pov_gap_pc',\n",
    "           yaxis_title='Change in poverty gap',\n",
    "           title='Poverty gap by reform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving beyond poverty, we found that FPUC would have reduced overall inequality\n",
    "(as measured by the Gini index over individuals, considering their SPM unit's total resources)\n",
    "more than the universal payments, by a small but consistent margin.\n",
    "If anything, the payroll tax cut would slightly increase inequality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "line_graph(pov_gap_ineq2, group='fpuc', y='gini_pc',\n",
    "           yaxis_title='Change in Gini index',\n",
    "           title='Inequality by reform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving forward\n",
    "\n",
    "While FPUC and universal transfers performed similarly in the baseline case,\n",
    "universal transfers reduce poverty and inequality significantly more than expanding\n",
    "FPUC, given that FPUC had already been in effect from April through July.\n",
    "The difference is larger in worse economic times (2009 vs. 2018),\n",
    "when using the poverty gap measure to consider poverty depth, and is especially\n",
    "pronounced for child and Black poverty.\n",
    "\n",
    "The intuition behind these trends is that FPUC focuses resources on unemployed people,\n",
    "especially long-term unemployed. While these can be similarly poor to people not in the labor force,\n",
    "who constitute about half of the population in poverty, the first FPUC round helped this targeted\n",
    "group substantially. To reduce overall poverty, future resources are better spread out\n",
    "than adding more eggs to the unemployed basket.\n",
    "\n",
    "Starting with the poverty rate, we find that extending FPUC would have reduced\n",
    "poverty by 3.9 percent in 2009, compared to a baseline where FPUC had already\n",
    "been enacted from April through July. However, a budget-neutral universal payment\n",
    "would have reduce poverty twice as much--by 7.8 percent.\n",
    "An adult-only transfer would be somewhere in the middle, and a payroll tax cut\n",
    "would reduce poverty by less than half as much as the FPUC extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Round for the hover text.\n",
    "line_graph(pov_rates2[(pov_rates2.age_group == 'All') &\n",
    "                      (pov_rates2.race == 'All')],\n",
    "           group='fpuc2', y='pov_pc',\n",
    "           yaxis_title='Change in SPM poverty rate',\n",
    "           title='Poverty reduction by reform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering poverty depth with the poverty gap measure shows that a universal payment\n",
    "would have nearly three times the effect of extending FPUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Round for the hover text.\n",
    "line_graph(pov_gap_ineq2, group='fpuc2', y='pov_gap_pc',\n",
    "           yaxis_title='Change in poverty gap',\n",
    "           title='Poverty gap by reform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the initial FPUC reduced inequality more than universal transfers in every year,\n",
    "the opposite is true of the FPUC expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "line_graph(pov_gap_ineq2, group='fpuc2', y='gini_pc',\n",
    "           yaxis_title='Change in Gini index',\n",
    "           title='Inequality by reform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For both child and Black poverty, the universal payments have more than double\n",
    "the effect of FPUC extension. Unsurprisingly, the adult-only restriction\n",
    "dramatically reduces the effectiveness of the payments for reducing child poverty\n",
    "specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "line_graph(pov_rates2[(pov_rates2.age_group == 'Children') &\n",
    "                      (pov_rates2.race == 'All')],\n",
    "           group='fpuc2', y='pov_pc',\n",
    "           yaxis_title='Change in child SPM poverty rate',\n",
    "           title='Child poverty reduction by reform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "line_graph(pov_rates2[(pov_rates2.age_group == 'All') &\n",
    "                      (pov_rates2.race == 200)],\n",
    "           group='fpuc2', y='pov_pc',\n",
    "           yaxis_title='Change in Black SPM poverty rate',\n",
    "           title='Black poverty reduction by reform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
